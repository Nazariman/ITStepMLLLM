from langchain_google_genai import GoogleGenerativeAI

import dotenv
import os

# завантажити api ключі з папки .env
dotenv.load_dotenv()

# отримати сам ключ
api_key = os.getenv('GEMINI_API_KEY')

# створення моделі
# Велика мовна модель(llm)

# llm = GoogleGenerativeAI(
#     model='gemini-2.0-flash',  # назва моделі
#     google_api_key=api_key,    # ваша API
# )
#
# # запуск моделі
# response = llm.invoke("Привіт, що таке LLM?")
# print(response)

# як воно працює?
# текст(запит) ділиться на токен(слова але не тільки)
# для прикладу вище токени такі
# <START> Привіт , що таке LLM ? <END>

# модель отримує запит і шматок готової відповіді

# Запит: <START> Привіт , що таке LLM ? <END>
# Відповідь: <START> Привіт LLM це

# Для кожного слова отримуємо ймовірність
# що це слово має бути наступним
# модель -- 20%
# велика -- 18%
# технологія -- 10%
# яблуко -- 0,000000001%

# параметри моделі

llm = GoogleGenerativeAI(
    model='gemini-2.0-flash',  # назва моделі
    google_api_key=api_key,    # ваша API
    #top_k=10,                  # серед скількох найбільш ймовірних слів обирати нове слово
    temperature=1.7,            # температура
    max_output_tokens=20        # максимальна довжина відповіді у токенах
)

# температура відповідає за креативність відповіді
# 0 - 0,3 -- мала креативність(відповіді чіткі та ясні)
# 0,4 - 1,2 -- середня креативність(відповіді інформативні, модель дає більш живі відподі)
# 1,5 - 2,0 -- велика креативність(підходить для генерації текстів, створення історій)
# 2.0 >   -- галюцинації


# запуск моделі
response = llm.invoke("Привіт, що таке LLM?")
print(response)